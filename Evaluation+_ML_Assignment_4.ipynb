{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fwi4m_tQr1xs",
    "outputId": "9eafdd6e-ecd4-41c5-d7de-e31f3d8fe546"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Pjr69ChG81L2KEQLPs-dA6eW4RUCkBsD\n",
      "To: C:\\Faaiq\\Course Resources\\Semester 4\\Machine Learning\\Assignment 4\\PA4_dataset.zip\n",
      "\n",
      "  0%|          | 0.00/322k [00:00<?, ?B/s]\n",
      "100%|##########| 322k/322k [00:00<00:00, 583kB/s]\n",
      "100%|##########| 322k/322k [00:00<00:00, 583kB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1Pjr69ChG81L2KEQLPs-dA6eW4RUCkBsD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZqsE9MlNsVqv",
    "outputId": "9751f7a2-9cd4-4505-fc33-e9f0e502a63b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# !unzip PA4_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8cSqgtFs9xH"
   },
   "source": [
    "Loaded dataset, pre-processing now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MHOWDRdutDCx"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TNvEDdByCbuq"
   },
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv(\"PA4_dataset/test.csv\")\n",
    "dataset_train = pd.read_csv(\"PA4_dataset/train.csv\")\n",
    "stop_words_doc = pd.read_csv(\"PA4_dataset/stop_words.txt\", header=None)\n",
    "stop_words = stop_words_doc[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9eeU-WIcEqbz"
   },
   "outputs": [],
   "source": [
    "# separating the sentiment data and the tweet content\n",
    "test_sentiment = dataset_test.iloc[:,0]\n",
    "train_sentiment = dataset_train.iloc[:,0]\n",
    "test_tweets = dataset_test.iloc[:,1]\n",
    "train_tweets = dataset_train.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSSdU9x3h3uq"
   },
   "source": [
    "# Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "H9hIO1hzMzJA"
   },
   "outputs": [],
   "source": [
    "# Beginning preprocessing\n",
    "# modulating by making function instead\n",
    "def cleaning_data(dataframe, stopwords):\n",
    "    clean_list = []\n",
    "    for tweet in dataframe:\n",
    "        temp_string = tweet\n",
    "        # removing stop words\n",
    "        for word in stopwords:\n",
    "            word = \" \"+word\n",
    "            temp_string = re.sub(word,'',temp_string) \n",
    "        # remove hyperlinks\n",
    "        temp_string = re.sub('http[s]?://\\S+', '', tweet)\n",
    "        # remove numbers\n",
    "        temp_string = re.sub(r'[0-9]+', '', temp_string)\n",
    "        # remove usernames\n",
    "        temp_string = re.sub('@\\S+','',temp_string)\n",
    "        # remove all punctuation\n",
    "        temp_string = re.sub(r'[^\\w\\s]', '', temp_string)\n",
    "        # done removing, add back to original list\n",
    "        temp_string = temp_string.lower()\n",
    "        clean_list.append(temp_string)\n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r1a8Cs1aRDOY",
    "outputId": "a8caa39f-c20e-4596-9d50-ad9aebbde563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       @USAirways thanks to the whole team for an on-...\n",
      "1       @VirginAmerica gives positive outlook, but see...\n",
      "2       @JetBlue Hey Jetblue, you Cancelled Flightled ...\n",
      "3       @united @PGATOUR @NTrustOpen Next thing you kn...\n",
      "4       @SouthwestAir why can't you help me after you ...\n",
      "                              ...                        \n",
      "1459    @AmericanAir after waiting for a delayed plane...\n",
      "1460    @VirginAmerica what is going on with customer ...\n",
      "1461    @SouthwestAir I will tell marry a lamp if you ...\n",
      "1462    @USAirways I got an email asking me to checkin...\n",
      "1463        @USAirways @AmericanAir no, don't leave me!!!\n",
      "Name: Tweet, Length: 1464, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "# pd.reset_option(\"all\")\n",
    "print(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dDW5-dvd0g3G"
   },
   "outputs": [],
   "source": [
    "clean_test_tweets = cleaning_data(test_tweets, stop_words)\n",
    "clean_train_tweets = cleaning_data(train_tweets, stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfWU1amocqel"
   },
   "source": [
    "Data Preprocessing done.\n",
    "Removed the following in order: \n",
    "\n",
    "\n",
    "*   Stop words first, as they contained punctuation.\n",
    "*   All usernames (everything starting with @)\n",
    "*   Punctuation\n",
    "*   Lowercase\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgZZBcU5hhMo"
   },
   "source": [
    "# Part 2: Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8opAJ_5jhal1"
   },
   "outputs": [],
   "source": [
    "# Construct a vocabulary of all the words first\n",
    "def vocabulary_construction(dataset):\n",
    "    vocab = []\n",
    "    for string in dataset:\n",
    "        string_split = string.split()\n",
    "        for word in string_split:\n",
    "            if word not in vocab:\n",
    "                vocab.append(word)\n",
    "    return vocab\n",
    "# run given function to produce training vocabulary\n",
    "train_vocab = vocabulary_construction(clean_train_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oeFpqBMukUha"
   },
   "outputs": [],
   "source": [
    "num_train_tweets = len(clean_train_tweets)\n",
    "num_test_tweets = len(clean_train_tweets)\n",
    "\n",
    "def populate_bog(dataset, vocab):\n",
    "    vocab_size = len(vocab)\n",
    "    dataset_size = len(dataset)\n",
    "    bag_of_words = np.zeros((dataset_size, vocab_size), dtype='int')\n",
    "    for i in range(dataset_size):\n",
    "        for word in dataset[i]:\n",
    "            try:\n",
    "                position = vocab.index(word)\n",
    "                bag_of_words[i,position] += 1\n",
    "            except:\n",
    "                pass\n",
    "    return bag_of_words\n",
    "\n",
    "# running to generate bag of words for test and training datasets\n",
    "train_bog = populate_bog(clean_train_tweets, train_vocab)\n",
    "test_bog = populate_bog(clean_test_tweets, train_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4z2MjAKB_xN"
   },
   "source": [
    "# Part 3: Logistic Regression from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_oMyNpYnM-rt"
   },
   "outputs": [],
   "source": [
    "def sigmoid_function(x_vector, weight_vector):\n",
    "    z_value = np.dot(x_vector, weight_vector)\n",
    "    z_value += weight_vector[0]\n",
    "    to_return = 1/(1+np.exp(-1*z_value))\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "j8X8qac-BvhZ"
   },
   "outputs": [],
   "source": [
    "# cross entropy function calls sigmoid function\n",
    "def cross_entropy_loss(label_set, input_dataset, weight_vector):\n",
    "    sum = 0\n",
    "    bias = weight_vector[0]\n",
    "    label_size = len(label_set)\n",
    "    for i in range(label_size):\n",
    "        x_vector = input_dataset[i]\n",
    "        y_label = label_set[i]\n",
    "        hypothesis_value = sigmoid_function(x_vector, weight_vector) # using first index onwards of the actual weight vector, as the 0th index has the bias value\n",
    "        current_value = y_label*np.log(hypothesis_value)+(1-y_label)*np.log(1-hypothesis_value)\n",
    "        sum += current_value\n",
    "    return -1*sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2-IKlu9gmj9V"
   },
   "outputs": [],
   "source": [
    "# preparing dataset for logistic regression\n",
    "# making label vector for every case\n",
    "def label_preparation(label, dataset):\n",
    "    label_list = []\n",
    "    for datapoint in dataset:\n",
    "        if datapoint == label:\n",
    "            label_list.append(1)\n",
    "        else:\n",
    "            label_list.append(0)\n",
    "    return label_list\n",
    "\n",
    "neg_train_label_list = label_preparation('negative', train_sentiment)\n",
    "pos_train_label_list = label_preparation('positive', train_sentiment)\n",
    "neut_train_label_list = label_preparation('neutral', train_sentiment)\n",
    "\n",
    "neg_test_label_list = label_preparation('negative', test_sentiment)\n",
    "pos_test_label_list = label_preparation('positive', test_sentiment)\n",
    "neut_test_label_list = label_preparation('neutral', test_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YkadrV8uP4C6"
   },
   "outputs": [],
   "source": [
    "# training using gradient descent\n",
    "def gradient_descent(initial_weights, dataset, label_vector, regular_param, epochs, lr):\n",
    "    # lr is learning rate\n",
    "    current_weights = initial_weights\n",
    "    for epoch in range(epochs):\n",
    "        sum = 0\n",
    "        bias = 0\n",
    "        for index, x_vector in enumerate(dataset):\n",
    "            expression = sigmoid_function(x_vector, current_weights)\n",
    "            label = label_vector[index]\n",
    "            expression -= label\n",
    "            bias_delta = expression\n",
    "            expression = expression*x_vector\n",
    "            sum += expression\n",
    "            bias += bias_delta\n",
    "        sum += 2*regular_param*current_weights[1:]\n",
    "        bias += 2*regular_param*current_weights[0]\n",
    "        current_weights[1:] = current_weights[1:] - lr*expression\n",
    "        current_weights[0] = current_weights[0] - lr*bias \n",
    "    return current_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MNmI3xWneIyp"
   },
   "outputs": [],
   "source": [
    "def gradient_descent_vectorized(initial_weights, dataset, label_vector, regular_param, epochs, lr):\n",
    "    current_weights = initial_weights\n",
    "    for epoch in range(epochs):\n",
    "        expression_vector = sigmoid_function(dataset, current_weights)\n",
    "        expression_vector -= label_vector\n",
    "        bias = np.sum(expression_vector)\n",
    "        product = np.multiply(expression_vector, dataset.transpose())\n",
    "        sum = np.sum(product, axis=1)\n",
    "        delta_weights = sum + 2*regular_param*current_weights\n",
    "        # delta_bias = bias + 2*regular_param*current_weights[0]\n",
    "        # current_weights[1:] = current_weights[1:] - lr*delta_weights\n",
    "        # current_weights[0] - current_weights[0] - lr*delta_bias\n",
    "        current_weights = current_weights - lr/len(label_vector)*delta_weights\n",
    "    return current_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KJecKMa6q23r"
   },
   "outputs": [],
   "source": [
    "def predict(dataset, weight_matrix):\n",
    "    predicted_labels = []\n",
    "    for x_vector in dataset:\n",
    "        predictions_list = []\n",
    "        for weight_vector in weight_matrix:\n",
    "            predictions_list.append(prediction_helper(x_vector, weight_vector))\n",
    "        predicted_label = predictions_list.index(max(predictions_list))\n",
    "        predicted_labels.append(predicted_label)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Jza3yl95sdrw"
   },
   "outputs": [],
   "source": [
    "def prediction_helper(x_vector, weight_vector):\n",
    "    resulting_probability = np.dot(x_vector, weight_vector)\n",
    "    # resulting_probability += 1*weight_vector[0]\n",
    "    return resulting_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-9Er5RiuKlF"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ksgXrOQb7CJh"
   },
   "outputs": [],
   "source": [
    "label_set = []\n",
    "label_set.append(neg_train_label_list)\n",
    "label_set.append(neut_train_label_list)\n",
    "label_set.append(pos_train_label_list)\n",
    "# neg,neut, pos = log_reg_training(train_bog, label_set, 1000, 0.01, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GQoanvNmuOTL"
   },
   "outputs": [],
   "source": [
    "def log_reg_training(dataset, label_set, epochs, lr, regular_param):\n",
    "    initial_weights = np.zeros(len(dataset[0]))\n",
    "    negative_weights = gradient_descent_vectorized(initial_weights, dataset, label_set[0], regular_param, epochs, lr)\n",
    "    # print('done with negative')\n",
    "    neutral_weights = gradient_descent_vectorized(initial_weights, dataset, label_set[1], regular_param, epochs, lr)\n",
    "    # print('done with neutral')\n",
    "    positive_weights = gradient_descent_vectorized(initial_weights, dataset, label_set[2], regular_param, epochs, lr)\n",
    "    # print('done with positive')\n",
    "    weights_set = []\n",
    "    weights_set.append(negative_weights)\n",
    "    weights_set.append(neutral_weights)\n",
    "    weights_set.append(positive_weights)\n",
    "    return weights_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "dB6giQ2pML93",
    "outputId": "5aad3bb8-fcce-4540-ca94-1c2006b08e61"
   },
   "outputs": [],
   "source": [
    "e1000_set1 = log_reg_training(train_bog, label_set, 1000, 0.0001, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAKKxmxs-nX2"
   },
   "outputs": [],
   "source": [
    "# computing all with 1000 epochs\n",
    "e1000_set1 = log_reg_training(train_bog, label_set, 1000, 0.0001, 1)\n",
    "e1000_set2 = log_reg_training(train_bog, label_set, 1000, 0.001, 1)\n",
    "e1000_set3 = log_reg_training(train_bog, label_set, 1000, 0.01, 1)\n",
    "e1000_set4 = log_reg_training(train_bog, label_set, 1000, 0.1, 1)\n",
    "e1000_set5 = log_reg_training(train_bog, label_set, 1000, 0.0001, 10)\n",
    "e1000_set6 = log_reg_training(train_bog, label_set, 1000, 0.001, 10)\n",
    "e1000_set7 = log_reg_training(train_bog, label_set, 1000, 0.01, 10)\n",
    "e1000_set8 = log_reg_training(train_bog, label_set, 1000, 0.1, 10)\n",
    "e1000_set9 = log_reg_training(train_bog, label_set, 1000, 0.0001, 0.1)\n",
    "e1000_set10 = log_reg_training(train_bog, label_set, 1000, 0.001, 0.1)\n",
    "e1000_set11 = log_reg_training(train_bog, label_set, 1000, 0.01, 0.1)\n",
    "e1000_set12 = log_reg_training(train_bog, label_set, 1000, 0.1, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mn_OgbxcJR34"
   },
   "outputs": [],
   "source": [
    "# computing all with 800 epochs\n",
    "e800_set1 = log_reg_training(train_bog, label_set, 800, 0.0001, 1)\n",
    "e800_set2 = log_reg_training(train_bog, label_set, 800, 0.001, 1)\n",
    "e800_set3 = log_reg_training(train_bog, label_set, 800, 0.01, 1)\n",
    "e800_set4 = log_reg_training(train_bog, label_set, 800, 0.1, 1)\n",
    "e800_set5 = log_reg_training(train_bog, label_set, 800, 0.0001, 10)\n",
    "e800_set6 = log_reg_training(train_bog, label_set, 800, 0.001, 10)\n",
    "e800_set7 = log_reg_training(train_bog, label_set, 800, 0.01, 10)\n",
    "e800_set8 = log_reg_training(train_bog, label_set, 800, 0.1, 10)\n",
    "e800_set9 = log_reg_training(train_bog, label_set, 800, 0.0001, 0.1)\n",
    "e800_set10 = log_reg_training(train_bog, label_set, 800, 0.001, 0.1)\n",
    "e800_set11 = log_reg_training(train_bog, label_set, 800, 0.01, 0.1)\n",
    "e800_set12 = log_reg_training(train_bog, label_set, 800, 0.1, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zbA1A1nJ1-F"
   },
   "outputs": [],
   "source": [
    "# computing all with 500 epochs\n",
    "e500_set1 = log_reg_training(train_bog, label_set, 500, 0.0001, 1)\n",
    "e500_set2 = log_reg_training(train_bog, label_set, 500, 0.001, 1)\n",
    "e500_set3 = log_reg_training(train_bog, label_set, 500, 0.01, 1)\n",
    "e500_set4 = log_reg_training(train_bog, label_set, 500, 0.1, 1)\n",
    "e500_set5 = log_reg_training(train_bog, label_set, 500, 0.0001, 10)\n",
    "e500_set6 = log_reg_training(train_bog, label_set, 500, 0.001, 10)\n",
    "e500_set7 = log_reg_training(train_bog, label_set, 500, 0.01, 10)\n",
    "e500_set8 = log_reg_training(train_bog, label_set, 500, 0.1, 10)\n",
    "e500_set9 = log_reg_training(train_bog, label_set, 500, 0.0001, 0.1)\n",
    "e500_set10 = log_reg_training(train_bog, label_set, 500, 0.001, 0.1)\n",
    "e500_set11 = log_reg_training(train_bog, label_set, 500, 0.01, 0.1)\n",
    "e500_set12 = log_reg_training(train_bog, label_set, 500, 0.1, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "El6v-TbKK-IS"
   },
   "outputs": [],
   "source": [
    "# computing all with 200 epochs\n",
    "e200_set1 = log_reg_training(train_bog, label_set, 200, 0.0001, 1)\n",
    "e200_set2 = log_reg_training(train_bog, label_set, 200, 0.001, 1)\n",
    "e200_set3 = log_reg_training(train_bog, label_set, 200, 0.01, 1)\n",
    "e200_set4 = log_reg_training(train_bog, label_set, 200, 0.1, 1)\n",
    "e200_set5 = log_reg_training(train_bog, label_set, 200, 0.0001, 10)\n",
    "e200_set6 = log_reg_training(train_bog, label_set, 200, 0.001, 10)\n",
    "e200_set7 = log_reg_training(train_bog, label_set, 200, 0.01, 10)\n",
    "e200_set8 = log_reg_training(train_bog, label_set, 200, 0.1, 10)\n",
    "e200_set9 = log_reg_training(train_bog, label_set, 200, 0.0001, 0.1)\n",
    "e200_set10 = log_reg_training(train_bog, label_set, 200, 0.001, 0.1)\n",
    "e200_set11 = log_reg_training(train_bog, label_set, 200, 0.01, 0.1)\n",
    "e200_set12 = log_reg_training(train_bog, label_set, 200, 0.1, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "vywGBOXoLMrC"
   },
   "outputs": [],
   "source": [
    "# computing all with 100 epochs\n",
    "e100_set1 = log_reg_training(train_bog, label_set, 100, 0.0001, 1)\n",
    "e100_set2 = log_reg_training(train_bog, label_set, 100, 0.001, 1)\n",
    "e100_set3 = log_reg_training(train_bog, label_set, 100, 0.01, 1)\n",
    "e100_set4 = log_reg_training(train_bog, label_set, 100, 0.1, 1)\n",
    "e100_set5 = log_reg_training(train_bog, label_set, 100, 0.0001, 10)\n",
    "e100_set6 = log_reg_training(train_bog, label_set, 100, 0.001, 10)\n",
    "e100_set7 = log_reg_training(train_bog, label_set, 100, 0.01, 10)\n",
    "e100_set8 = log_reg_training(train_bog, label_set, 100, 0.1, 10)\n",
    "e100_set9 = log_reg_training(train_bog, label_set, 100, 0.0001, 0.1)\n",
    "e100_set10 = log_reg_training(train_bog, label_set, 100, 0.001, 0.1)\n",
    "e100_set11 = log_reg_training(train_bog, label_set, 100, 0.01, 0.1)\n",
    "e100_set12 = log_reg_training(train_bog, label_set, 100, 0.1, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIXMiaJiEfxb"
   },
   "outputs": [],
   "source": [
    "# random training\n",
    "e200_set2 = log_reg_training(train_bog, label_set, 200, 0.001, 3)\n",
    "e200_set22 = log_reg_training(train_bog, label_set, 200, 0.001, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvMHNFGiL3C7"
   },
   "outputs": [],
   "source": [
    "e500_set1 = log_reg_training(train_bog, label_set, 500, 0.0001, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeKH8IgBIvFC",
    "outputId": "919c6923-b018-4f5d-e356-4205ad906803",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# print(list(set(e200_set2[0])))\n",
    "# print(list(set(e200_set2[1])))\n",
    "# print(list(set(e200_set2[2])))\n",
    "\n",
    "predictions_set1 = predict(test_bog, e1000_set1)\n",
    "print(predictions_set1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlGYuO_hLuo5"
   },
   "source": [
    "## Evaluation of Algorithm\n",
    "## (Functions to be used for evaluation of Part 5 as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "RaMI8pXE_en3"
   },
   "outputs": [],
   "source": [
    "def evaluation_function(predicted_labels, actual_labels):\n",
    "    # construct confusion matrix\n",
    "    # report accuracy\n",
    "    # report f1 score\n",
    "    num_predictions = len(predicted_labels)\n",
    "    correct_count = 0\n",
    "    # constructing confusion matrix\n",
    "    confusion_matrix = np.zeros((3,3))\n",
    "    # 0 is negative, 1 is neutral, 2 is positive\n",
    "    for i in range(num_predictions):\n",
    "        if predicted_labels[i] == actual_labels[i]:\n",
    "            correct_count += 1\n",
    "        # confusion_matrix[predicted_labels[i]][actual_labels[i]] += 1\n",
    "        confusion_matrix[predicted_labels[i], actual_labels[i]] += 1\n",
    "    accuracy = correct_count/num_predictions\n",
    "\n",
    "    # computing macro averages\n",
    "    # computing recall\n",
    "    recall_0 = confusion_matrix[0,0]/np.sum(confusion_matrix[:,0])\n",
    "    recall_1 = confusion_matrix[1,1]/np.sum(confusion_matrix[:,1])\n",
    "    recall_2 = confusion_matrix[2,2]/np.sum(confusion_matrix[:,2])\n",
    "\n",
    "    # computing precision\n",
    "    try:\n",
    "        precision_0 = confusion_matrix[0,0]/np.sum(confusion_matrix[0])\n",
    "    except:\n",
    "        precision_0 = 0\n",
    "    try:\n",
    "        precision_1 = confusion_matrix[1,1]/np.sum(confusion_matrix[1])\n",
    "    except:\n",
    "        precision_1 = 0\n",
    "    try:\n",
    "        precision_2 = confusion_matrix[2,2]/np.sum(confusion_matrix[2])\n",
    "    except: precision_2 = 0\n",
    "\n",
    "    macro_avg_recall = (recall_0 + recall_1 + recall_2)/3\n",
    "    print(macro_avg_recall)\n",
    "    macro_avg_precision = (precision_0 + precision_1 + precision_2)/3\n",
    "    print(macro_avg_precision)\n",
    "\n",
    "    macro_f1_score = 2*macro_avg_recall*macro_avg_precision/(macro_avg_recall+macro_avg_precision)\n",
    "    print('macro f1', macro_f1_score)\n",
    "    print(confusion_matrix)\n",
    "    return accuracy, confusion_matrix, macro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTmk4q9DFKWW",
    "outputId": "76903c89-032d-4f44-c19a-5de9eb73b5c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1464\n",
      "1464\n",
      "0.3333333333333333\n",
      "nan\n",
      "macro f1 nan\n",
      "[[924. 301. 239.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-bfbfb72a4ca4>:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision_1 = confusion_matrix[1,1]/np.sum(confusion_matrix[1])\n",
      "<ipython-input-24-bfbfb72a4ca4>:33: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision_2 = confusion_matrix[2,2]/np.sum(confusion_matrix[2])\n"
     ]
    }
   ],
   "source": [
    "# predictions_set1 = predict(test_bog, e1000_set1)\n",
    "# print(list(set(e1000_set1[0])))\n",
    "# print(list(set(e1000_set1[1])))\n",
    "# print(list(set(e1000_set1[2])))\n",
    "print(len(predictions_set1))\n",
    "print(len(encoded_test_labels))\n",
    "_,_, _ = evaluation_function(predictions_set1, encoded_test_labels)\n",
    "# print(predictions_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "CH5jcreHEjeG"
   },
   "outputs": [],
   "source": [
    "# encoding of the actual labels\n",
    "encoded_train_labels = []\n",
    "for label in train_sentiment:\n",
    "    if label == 'positive':\n",
    "        encoded_train_labels.append(2)\n",
    "    elif label == 'neutral':\n",
    "        encoded_train_labels.append(1)\n",
    "    elif label == 'negative':\n",
    "        encoded_train_labels.append(0)\n",
    "\n",
    "encoded_test_labels = []\n",
    "for label in test_sentiment:\n",
    "    if label == 'positive':\n",
    "        encoded_test_labels.append(2)\n",
    "    elif label == 'neutral':\n",
    "        encoded_test_labels.append(1)\n",
    "    elif label == 'negative':\n",
    "        encoded_test_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "-Rfgot46FJf_"
   },
   "outputs": [],
   "source": [
    "def compute_loss(dataset, label_set, weight_vector):\n",
    "    loss = 0\n",
    "    for i in range(3):\n",
    "        loss += cross_entropy_loss(label_set[i], dataset, weight_vector[i])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "asO5rg-vL5Pi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8984.449825398075\n"
     ]
    }
   ],
   "source": [
    "loss1 = compute_loss(train_bog, label_set, e1000_set1)\n",
    "print(loss1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ly_FJrrONBMK"
   },
   "source": [
    "# Part 4: Logistic Regression using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-00uG-qrNHri",
    "outputId": "0a77ed80-a74a-43ee-d6a8-ff6955d6f7b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_reg = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
    "logistic_reg.fit(train_bog, train_sentiment) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPcPjyqaPysP"
   },
   "source": [
    "The model is trained using the training bag of words as the input data, along with the labels passed as 'negative', 'positive', or 'neutral'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDSOg3DxNB-P",
    "outputId": "a7bd262e-16ba-4539-ae34-3e7efac63ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80       924\n",
      "     neutral       0.47      0.29      0.36       301\n",
      "    positive       0.60      0.21      0.31       239\n",
      "\n",
      "    accuracy                           0.67      1464\n",
      "   macro avg       0.59      0.47      0.49      1464\n",
      "weighted avg       0.64      0.67      0.63      1464\n",
      "\n",
      "Confusion Matrix:\n",
      "1. Negative, 2. Neutral 3. Positive - this is applicable for both rows and columns\n",
      "[[850  58  16]\n",
      " [196  88  17]\n",
      " [150  40  49]]\n"
     ]
    }
   ],
   "source": [
    "predictions = logistic_reg.predict(test_bog)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "report = classification_report(test_sentiment, predictions)\n",
    "con_mat = confusion_matrix(test_sentiment, predictions)\n",
    "print(report)\n",
    "print('Confusion Matrix:')\n",
    "print('1. Negative, 2. Neutral 3. Positive - this is applicable for both rows and columns')\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GYkEtX8PDyN"
   },
   "source": [
    "The confusion matrix has been plotted above. The accuracy comes out to be roughly 0.67. The macro average of the f1 score is 0.49, while the weighted average of the f1-score is 0.63. As can be seen, there is much more data available for the negative sentiment as compared to neutral and positive tweets. Furthermore, the f1 score is generally high for negative tweets as well, showing that the classifier performs generally better in that case.\n",
    "\n",
    "Summary:\n",
    "<br>\n",
    "Accuracy: 0.67\n",
    "<br>Macro Average F1-score: 0.49\n",
    "<br>Weighted Average F1-score: 0.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUlfrEuTP_NO"
   },
   "source": [
    "# Part 5: Implementation of Naive Bayes Classifier from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFZt7AFAQF5X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn4UoH1X_HNL"
   },
   "source": [
    "# Part 6: Scikit-Learn implementation of Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2k6KBf3_gc3",
    "outputId": "4ccca069-c19f-40af-dc4d-14f80d9c3183"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_skl_model = MultinomialNB()\n",
    "NB_skl_model.fit(train_bog, train_sentiment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdqHfI7PA_mO",
    "outputId": "b6fa8049-ebd9-47d1-fe3b-456770a68e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      1.00      0.77       924\n",
      "     neutral       0.00      0.00      0.00       301\n",
      "    positive       0.00      0.00      0.00       239\n",
      "\n",
      "    accuracy                           0.63      1464\n",
      "   macro avg       0.21      0.33      0.26      1464\n",
      "weighted avg       0.40      0.63      0.49      1464\n",
      "\n",
      "Confusion Matrix\n",
      "[[924   0   0]\n",
      " [301   0   0]\n",
      " [239   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "NB_predictions = NB_skl_model.predict(test_bog)\n",
    "nb_report = classification_report(test_sentiment, NB_predictions)\n",
    "nb_con_mat = confusion_matrix(test_sentiment, NB_predictions)\n",
    "print(nb_report)\n",
    "print('Confusion Matrix')\n",
    "print(nb_con_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNpmcTRgC-uy"
   },
   "source": [
    "For some reason, the NB classifier is giving the same prediction for all inputs. I used the following resource to help make sense of this: https://datascience.stackexchange.com/questions/58302/multinomial-naive-bayes-giving-wrong-result\n",
    "\n",
    "As we have substantially more data for negative tweets, along with the fact that we indexed negative tweets at 0, even if the computed probability came out to be exactly equal, the model predicts the tweet to be negative simply by virtue of negative tweets being indexed first.\n",
    "As a whole, the entire confusion matrix, f1-score and macro average is a meaningless evaluation in this case, as the model is just predicting tweets to be negative. Furthermore, the accuracy score is not far off from the accuracy of our logistic regression model. This shows the overwhelming support of negative tweets in our dataaset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Tc_NoMaDn-5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Evaluation+ ML Assignment 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
